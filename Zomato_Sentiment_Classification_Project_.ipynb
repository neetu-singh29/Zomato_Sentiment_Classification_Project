{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "w6K7xa23Elo4"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Zomato Sentiment Classification Project.\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA/Classification/Unsupervised\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member -** Neetu Singh\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… **Project Summary :**\n",
        "In this Zomato Restaurant Sentiment Classification project, we performed an end-to-end Data Science pipeline involving data wrangling, visualization, hypothesis testing, feature engineering, machine learning modeling, and model deployment readiness. The primary goal of this project was to analyze restaurant reviews and predict customer sentiment (Positive, Neutral, Negative), which can help Zomato and restaurant owners improve services, marketing, and customer experience.\n",
        "\n",
        "* We used **two** datasets:\n",
        "1. **Zomato Restaurant Names & Metadata** (contains restaurant-specific information like cost, cuisines, collections, timings, etc.).\n",
        "2. **Zomato Restaurant Reviews** (contains user reviews, ratings, metadata, time, and more).\n",
        "\n",
        "ðŸ“Š **Data Exploration & Preprocessing:**\n",
        "* First, we merged both datasets on **Restaurant Name**, resulting in a consolidated dataset containing both review text and restaurant-specific metadata.\n",
        "* Missing values were handled appropriately:\n",
        " * **Numerical columns **(e.g., Cost, Ratings, Pictures) filled with **median** values.\n",
        " * **Categorical columns** filled with mode or placeholders.\n",
        "* Outliers in `Cost` were treated using the Interquartile Range (IQR) method.\n",
        " * **Feature engineering was applied to create new columns like:**\n",
        " * **`review_length`**: Number of characters in the review.\n",
        " * **`cuisine_count`**: Number of cuisines a restaurant offers.\n",
        " * **`Hour`**: Extracted review time hour.\n",
        " * **`review_word_count`**: Total words in each review.\n",
        "* Textual reviews were cleaned using NLP steps including **lowercasing, punctuation removal, stopword removal, lemmatization**, and vectorized using **TF-IDF** for ML modeling.\n",
        "\n",
        "ðŸ“ˆ **Visualization & EDA (15+ charts):**\n",
        "\n",
        "Following **UBM (Univariate, Bivariate, Multivariate)** analysis:\n",
        "\n",
        "*  **Univariate**: Histograms for cost and review lengths, count plots for cuisine counts.\n",
        "*  **Bivariate**: Boxplots, violin plots, scatter plots to analyze relationships between cost, ratings, and review length.\n",
        "*  **Multivariate**: Heatmaps and pairplots to explore feature correlations.\n",
        "* **Word clouds** generated to highlight frequently used terms in reviews.\n",
        "\n",
        "* **Insights:**\n",
        "* Cost and reviews are moderately correlated.\n",
        "* North Indian and Chinese cuisines dominate.\n",
        "* High-rated restaurants usually maintain moderate costs.\n",
        "* Review lengths are longer for higher-cost restaurants, indicating detailed feedback.\n",
        "\n",
        "**Sentiment Analysis:**\n",
        "\n",
        "**TextBlob** is used to perform sentiment analysis on customer reviews, categorizing them as **`Positive, Negative, or Neutral`**. This analysis provides a deeper understanding of customer perceptions and overall satisfaction levels.\n",
        "\n",
        "\n",
        "ðŸ” **Hypothesis Testing:**\n",
        "\n",
        "We formulated and tested three key business-related hypotheses:\n",
        "\n",
        "1. High-cost restaurants receive higher ratings.\n",
        "2. Restaurants with more cuisines tend to receive longer reviews.\n",
        "3. Rating distribution is independent of the restaurant collections type.\n",
        "\n",
        "Using **ANOVA and Chi-square tests**, we rejected/accepted hypotheses based on p-values and statistical significance.\n",
        "\n",
        "âš™ï¸ **Feature Selection & Engineering:**\n",
        "* Important features for modeling: **`Cost_log`, `Rating`, `cuisine_count`, `review_length`, `review_word_count`, `Hour`**.\n",
        "* Data scaled using **StandardScaler** for optimal model performance.\n",
        "\n",
        "ðŸ¤– **Machine Learning Models & Tuning:**\n",
        "\n",
        "Three models were trained and evaluated:\n",
        "\n",
        "1. **Logistic Regression (Baseline model)**\n",
        "* Accuracy: 73.4%\n",
        "* Precision: 85.2%\n",
        "\n",
        "2. **Random Forest Classifier (Best Performing Model)**\n",
        "* Initial Accuracy: 82%, F1-score: 83%\n",
        "* After tuning (GridSearch): Accuracy improved to 82.6%, F1-score to 83.4%.\n",
        "\n",
        "3. **SVM (Support Vector Machine)**\n",
        "* Initial Accuracy: 73.7%\n",
        "* After tuning: Improved to 74.8%.\n",
        "\n",
        "ðŸ“Š **Evaluation Metrics for Business Impact:**\n",
        "* **Precision:** Ensures correct sentiment identification, important for user satisfaction.\n",
        "* **Recall:** Ensures no sentiment (especially negative) is missed.\n",
        "* **F1-Score:** Balanced metric for imbalanced datasets.\n",
        "* **Accuracy:** Overall correctness of model predictions.\n",
        "\n",
        "âœ… **Final Model & Deployment Readiness:**\n",
        "* **Random Forest Classifier (Tuned)** selected as final model.\n",
        "* Saved as **pickle file** for deployment.\n",
        "* Successfully tested on **unseen data**.\n",
        "* Ready for real-time prediction deployment via Flask/FastAPI APIs.\n",
        "\n",
        "ðŸš€ **Business Value:**\n",
        "* **Actionable insights** for restaurant owners to improve offerings.\n",
        "* **Sentiment analysis** helps Zomato tailor personalized recommendations and improve user retention.\n",
        "* Targeted marketing based on real-time sentiment trends."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**âœ… Problem Statement:**\n",
        "Zomato, one of India's leading food delivery and restaurant aggregation platforms, receives millions of customer reviews daily. These reviews contain valuable insights regarding customer experiences, preferences, and complaints. However, manually analyzing such vast textual data is infeasible and inefficient.\n",
        "\n",
        "**Objective**: The goal of this project is to build a Sen**timent Classification Machine Learning model** that can:\n",
        "\n",
        "* **Automatically classify customer reviews** into Positive, Neutral, and Negative categories.\n",
        "* Help Zomato and restaurant owners **identify strengths and areas of improvement**.\n",
        "* Enable **real-time tracking of customer sentiment** to improve customer engagement and satisfaction."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "from scipy.stats import ttest_ind, chi2_contingency, f_oneway\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler,OneHotEncoder,LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "df1 = pd.read_csv(\"Zomato Restaurant names and Metadata.csv\")\n",
        "df2 = pd.read_csv(\"Zomato Restaurant reviews.csv\")"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "# Display the first few rows both of the dataset\n",
        "display(df1.head())\n",
        "display(df2.head())"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "print(f\"Dataset Contain - Rows: {df1.shape[0]}, Columns: {df1.shape[1]}\")\n",
        "print(f\"Dataset Contain - Rows: {df2.shape[0]}, Columns: {df2.shape[1]}\")"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "# Check data information\n",
        "df1.info()\n",
        "df2.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "print(f\"Number of duplicate rows: {df1[df1.duplicated()].shape[0]}\")\n",
        "print(f\"Number of duplicate rows: {df2[df2.duplicated()].shape[0]}\")\n"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "\n",
        "\n",
        "# Missing Values/Null Values Count for dataframe1\n",
        "for df1, name in [(df1, 'df1')]:\n",
        "    print(f\"Missing Values/Null Values Count for {name}:\")\n",
        "    missing_values = df1.isnull().sum()\n",
        "    display(missing_values)\n",
        "\n",
        "    total_missing = missing_values.sum()\n",
        "    print(f\"\\nTotal missing values in {name}: {total_missing}\\n\")\n",
        "\n",
        "# Missing Values/Null Values Count for dataframe2\n",
        "for df2, name in [(df2, 'df2')]:\n",
        "    print(f\"Missing Values/Null Values Count for {name}:\")\n",
        "    missing_values = df2.isnull().sum()\n",
        "    display(missing_values)\n",
        "\n",
        "    total_missing = missing_values.sum()\n",
        "    print(f\"\\nTotal missing values in {name}: {total_missing}\\n\")"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(df1.isnull(),cbar=False,cmap='viridis')\n",
        "plt.title(\"Missing value in Dataframe\")\n",
        "plt.show()\n",
        "\n",
        "sns.heatmap(df2.isnull(),cbar=False,cmap='viridis')\n",
        "plt.title(\"Missing value in Dataframe\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** Based on the code execution, here's what we know about the **Zomato Restaurant datasets:**\n",
        "* **`df1 (Zomato Restaurant names and Metadata):`**\n",
        "1. **Shape:** The dataset has [number] rows and [number] columns.\n",
        "2. **Columns:** The columns include information like restaurant name, location, cuisines, average cost, ratings, etc.\n",
        "3. **Data Types:** Columns have various data types (object, float64, int64) representing different kinds of information.\n",
        "4. **Missing Values:** There are missing values in certain columns like [column names].\n",
        "5. **Duplicate Values:** There are [number] duplicate rows.\n",
        "\n",
        "* **`df2 (Zomato Restaurant reviews):`**\n",
        "1. **Shape:** The dataset has [number] rows and [number] columns.\n",
        "2. **Columns:** The columns include restaurant name, reviewer name, rating, review text, etc.\n",
        "3. **Data Types:** Columns have various data types (object, float64, int64) representing different kinds of information.\n",
        "4. **Missing Values:** There are missing values in certain columns like [column names].\n",
        "5. **Duplicate Values:** There are [number] duplicate rows.\n",
        "**Overall:**\n",
        "\n",
        "The datasets provide information about **restaurants, their metadata, and customer reviews**.\n",
        "\n",
        "There are **missing values** and **duplicate rows** that need to be handled during data wrangling.\n",
        "\n",
        "Further analysis is needed to understand the relationships between variables and gain deeper insights."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "\n",
        "df1_columns = df1.columns\n",
        "print(df1_columns)\n",
        "\n",
        "df2_columns = df2.columns\n",
        "print(df2_columns)"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "# Display summary statistics\n",
        "display(df1.describe())\n",
        "display(df2.describe())"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** Here's a description of each variable in the dataset:\n",
        "\n",
        "Provide a detailed description of each variable in both datasets (df1 and df2). Explain what each column represents and its significance in the context of the analysis."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "# Check Unique Values for each variable in df1 and df2 display the output\n",
        "print(\"Unique values in df1:\")\n",
        "display(df1.apply(pd.unique))\n",
        "\n",
        "print(\"\\nUnique values in df2:\")\n",
        "display(df2.apply(pd.unique))\n"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge datasets on restaurant name\n",
        "merged_df = pd.merge(df2,df1, on=\"Restaurant Name\", how=\"left\")"
      ],
      "metadata": {
        "id": "5vo7EZXrWe1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display after merging dataset and count\n",
        "display(merged_df.head())\n",
        "\n",
        "print(f\"Dataset Contain - Rows: {merged_df.shape[0]}, Columns: {merged_df.shape[1]}\")\n",
        "\n",
        "df_columns = merged_df.columns\n",
        "print(df_columns)"
      ],
      "metadata": {
        "id": "5tVNIFmdyPsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "\n",
        "#ðŸ”µ --------------------- 1. Handling Missing Values ------------------\n",
        "\n",
        "print(\"\\n âœ” Missing values before handling:\\n\", merged_df.isnull().sum())\n",
        "\n",
        "# Ensure 'Cost' is string to handle comma removal\n",
        "merged_df['Cost'] = merged_df['Cost'].astype(str).str.replace(\",\", \"\", regex=True)\n",
        "\n",
        "# Convert 'Cost' to numeric safely\n",
        "merged_df['Cost'] = pd.to_numeric(merged_df['Cost'], errors='coerce')\n",
        "\n",
        "# Fill numerical missing values using median\n",
        "numerical_cols = ['Rating', 'Pictures', 'Cost']\n",
        "for col in numerical_cols:\n",
        "    if merged_df[col].isnull().any():\n",
        "        merged_df[col] = pd.to_numeric(merged_df[col], errors='coerce')\n",
        "        median_value = merged_df[col].median()\n",
        "        merged_df[col] = merged_df[col].fillna(median_value)\n",
        "\n",
        "# Fill categorical missing values with mode or placeholder\n",
        "categorical_cols = ['Restaurant Name', 'Reviewer', 'Review', 'Metadata', 'Time',\n",
        "                    'Links', 'Collections', 'Cuisines', 'Timings']\n",
        "for col in categorical_cols:\n",
        "    if merged_df[col].isnull().any():\n",
        "        mode_value = merged_df[col].mode()[0]\n",
        "        merged_df[col] = merged_df[col].fillna(mode_value)\n",
        "\n",
        "#ðŸ”µ--------------------- 2. Handling Outliers ------------------------\n",
        "\n",
        "# Handling outliers in 'Cost' using IQR\n",
        "Q1 = merged_df['Cost'].quantile(0.25)\n",
        "Q3 = merged_df['Cost'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# âœ… MAKE A COPY to avoid SettingWithCopyWarning\n",
        "merged_df = merged_df.loc[(merged_df['Cost'] >= lower_bound) & (merged_df['Cost'] <= upper_bound)].copy()\n",
        "\n",
        "#ðŸ”µ --------------------- 3. Feature Engineering ----------------------\n",
        "\n",
        "# Review length (number of characters)\n",
        "merged_df['review_length'] = merged_df['Review'].apply(lambda x: len(str(x)))\n",
        "\n",
        "# Cuisine count (number of cuisines mentioned)\n",
        "merged_df['cuisine_count'] = merged_df['Cuisines'].apply(lambda x: len(str(x).split(',')))\n",
        "\n",
        "# Convert 'Time' to datetime safely\n",
        "merged_df['Time'] = pd.to_datetime(merged_df['Time'], errors='coerce')\n",
        "\n",
        "# Optional: Fill missing Time with mode (if needed)\n",
        "merged_df['Time'] = merged_df['Time'].fillna(merged_df['Time'].mode()[0])\n",
        "\n",
        "#ðŸ”µ---------------------- 4. Data Transformation (if needed)-------------------------------\n",
        "# Log transformation of 'Cost' for better distribution\n",
        "merged_df['Cost_log'] = np.log1p(merged_df['Cost'])  # log1p handles zero values safely\n",
        "\n",
        "#ðŸ”µ --------------------- Final Check -------------------------------\n",
        "print(\"\\n âœ” Missing values after handling:\\n\", merged_df.isnull().sum())\n",
        "print(\"\\nâœ… Final cleaned dataset ready for analysis!\\n\")\n",
        "display(merged_df.head())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PUNmzEc-axdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** âœ… **Data Wrangling Steps:**\n",
        "\n",
        "âœ… Manipulations and Cleaning Done:\n",
        "\n",
        "ðŸ”µ 1. **Handling Missing Values:**\n",
        "* **Checked and displayed missing values** before cleaning.\n",
        "* For `Cost:`\n",
        "* Removed commas and converted it to numeric safely.\n",
        "* Filled missing values with **median** of the column to handle skewed data.\n",
        "* For other **numerical columns** (`Rating, Pictures)`:\n",
        "* Filled missing values using **median** to prevent influence from outliers.\n",
        "* For **categorical columns** (`Restaurant Name, Reviewer, Review, Metadata, Time, Links, Collections, Cuisines, Timings`):\n",
        " * Filled missing values using **mode** (most frequent value) to ensure no empty records.\n",
        "* After this step, **no missing values remained** â€” making dataset complete and ready for analysis.\n",
        "\n",
        "ðŸ”µ **2. Handling Outliers (Cost column):**\n",
        "Applied Interquartile Range **(IQR)** method on `Cost` to:\n",
        "* Calculate lower and upper bounds.\n",
        "* Remove extreme outlier costs outside this range.\n",
        "* **Created a clean slice with only reasonable cost data** and used `.copy()` to avoid warnings.\n",
        "\n",
        "ðŸ”µ **3. Feature Engineering:**\n",
        "\n",
        "**Review Length:**\n",
        "* Created `review_length` to capture the **number of characters in each review.**\n",
        "* Helps in analyzing how detailed the reviews are.\n",
        "\n",
        "**Cuisine Count:**\n",
        "* Created cuisine_count to count the number of cuisines offered by each restaurant.\n",
        "* Helps analyze multi-cuisine vs. single-cuisine restaurants.\n",
        "\n",
        "* **Datetime Conversion:**\n",
        "* Converted `Time` column to proper `datetime` type for **time-based analysis**.\n",
        "* Filled missing `Time` values with mode to ensure consistency.\n",
        "\n",
        "* **Log Transformation of Cost:**\n",
        "* Created `Cost_log` to apply `log1p` (log transformation) on cost.\n",
        "* Helps in **normalizing skewed data** for better visualization and modeling.\n",
        "\n",
        "âœ… **Final Clean Dataset Columns:**\n",
        "\n",
        "**Column      :-\tDescription:**\n",
        "1. Restaurant Name:\tName of the restaurant\n",
        "2. Reviewer:\tName of reviewer\n",
        "3. Review:\tText review\n",
        "4. Rating:\tCustomer rating (numeric)\n",
        "5. Metadata\tReviews and followers info\n",
        "6. Time:\tReview date and time\n",
        "7. Pictures:\tNumber of pictures\n",
        "8. Links:\tZomato URL\n",
        "9. Cost:\tCost for two people (numeric, cleaned)\n",
        "10. Collections:\tRestaurant collections\n",
        "11. Cuisines:\tTypes of cuisines\n",
        "12. Timings:\tOperating timings\n",
        "13. review_length:\tLength of review in characters\n",
        "14. cuisine_count:\tNumber of cuisines offered\n",
        "15. Cost_log:\tLog transformed cost for normalization\n",
        "\n",
        "âœ… **Insights from Data Cleaning & Feature Engineering:**\n",
        "\n",
        "**Aspect\t:  Insights**\n",
        "* Missing Value Handling: \tAll missing values are filled; dataset is complete now.\n",
        "* Cost Distribution: \tOutliers removed to focus on realistic restaurant costs.\n",
        "* Review Analysis:\treview_length helps identify detailed vs. short reviews.\n",
        "* Cuisine Offering:\tcuisine_count shows restaurants offering multiple cuisines.\n",
        "* Time Readiness:\tTime ready for analyzing trends over time (day/month/year).\n",
        "* Cost Normalization:\tCost_log helps to normalize skewed cost for ML models.\n",
        "\n",
        "âœ… **Conclusion:**\n",
        "* Dataset is **fully cleaned and ready for EDA and ML modeling**.\n",
        "* Added **important derived features** to help understand customer reviews, restaurant diversity, and pricing better.\n",
        "* Outlier handling ensures **robust analysis without extreme values** affecting results."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### following the UBM (Univariate, Bivariate, Multivariate) rule:\n",
        "\n"
      ],
      "metadata": {
        "id": "n09ypGOoNAfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set style\n",
        "sns.set(style='whitegrid')"
      ],
      "metadata": {
        "id": "ConI2iwHfW10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1 : ðŸ“Š Histogram of Cost"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "\n",
        "# ------------------------------- 1. Histogram of Cost ----------------------------\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.histplot(merged_df['Cost'], bins=30, kde=True, color='skyblue')\n",
        "plt.title('Distribution of Cost for Two People')\n",
        "plt.xlabel('Cost')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** To understand the distribution of restaurant costs."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** Most restaurants are priced between â‚¹500 and â‚¹1500."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:**  Helps in menu pricing; no negative impact."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2 : ðŸ“Š Boxplot of Cost"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "\n",
        "# ------------------------------- 2. Boxplot of Cost ----------------------------\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.boxplot(x=merged_df['Cost'], color='lightgreen')\n",
        "plt.title('Boxplot of Restaurant Cost')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** To detect outliers and see cost spread."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** Some high-end restaurants exist but most are affordable. offered by restaurants in the dataset."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** Helps in pricing strategy; luxury segment insight.\n"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3 : ðŸ“ŠBarplot of Top 10 Cuisines"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "\n",
        "# ------------------------------- 3. Barplot of Top 10 Cuisines ----------------\n",
        "top_cuisines = merged_df['Cuisines'].str.split(', ').explode().value_counts().head(10)\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=top_cuisines.values, y=top_cuisines.index,hue=top_cuisines.index, palette='viridis')\n",
        "plt.legend([],[], frameon=False) #removing legend\n",
        "plt.title('Top 10 Most Popular Cuisines')\n",
        "plt.xlabel('Count')\n",
        "plt.ylabel('Cuisine')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** To identify most popular cuisines."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:**  North Indian and Chinese dominate the market."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:**  Menu design insights; focus on top cuisines."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Chart - 4 :ðŸ“ŠPie Chart for Collections"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "# ------------------------------- 4. Pie Chart for Collections -----------------\n",
        "collections = merged_df['Collections'].value_counts().head(5)\n",
        "plt.figure(figsize=(8,8))\n",
        "collections.plot.pie(autopct='%1.1f%%', startangle=140, colors=sns.color_palette('pastel'))\n",
        "plt.title('Top 5 Collections in Zomato')\n",
        "plt.ylabel('')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** To understand special restaurant collections."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** Specific collections like 'Hygiene Rated' are popular."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** Helps in marketing collections; positive impact."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5 : ðŸ“Š Heatmap of Correlation"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "# ------------------------------- 5. Heatmap of Correlation -------------------\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(merged_df[['Cost', 'Rating', 'review_length', 'cuisine_count']].corr(), annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** To check relationships among numerical variables."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** Moderate correlation between review length and cost."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** Indicates detailed reviews may relate to cost perception."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6 : ðŸ“Š Countplot of Ratings"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "# ------------------------------- 6. Countplot of Ratings ----------------------\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.countplot(x='Rating', data=merged_df, hue='Rating',  palette='mako')\n",
        "plt.title('Distribution of Ratings')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** To understand distribution of customer ratings."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** Majority give 4-5 star ratings."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** High customer satisfaction.\n"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7 : ðŸ“Š Violinplot of Cost vs Ratings"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "# ------------------------------- 7. Violinplot of Cost vs Ratings -------------\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.violinplot(x='Rating', y='Cost', data=merged_df, hue='Rating', palette='rocket')\n",
        "#sns.violinplot(x='Rating', y='Cost', data=merged_df, hue='Rating', dodge=False, palette='rocket')\n",
        "plt.legend([],[], frameon=False)\n",
        "plt.title('Cost Distribution across Ratings')\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "GjwW1JhtmCVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** To visualize cost distribution across ratings."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** High-rated places often moderately priced."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** Insights for value-for-money strategies.\n"
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8: ðŸ“Š Pair Plot: Rating, Cost, Pictures, Review Length,cuisine count"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 :  visualization code\n",
        "\n",
        "# ------------------------------- 8. Pairplot of Numerical Data ----------------\n",
        "sns.pairplot(merged_df[['Cost', 'Rating', 'Pictures', 'review_length', 'cuisine_count']])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** To explore pairwise relationships visually."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** Sparse but visible cost vs cuisine count trend."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** Helps identify data patterns; no negative insight.\n"
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9: ðŸ“Š  Scatterplot of Cost vs Review Length"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "\n",
        "# ------------------------------- 9. Scatterplot of Cost vs Review Length ------\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.scatterplot(x='review_length', y='Cost', data=merged_df, alpha=0.6)\n",
        "plt.title('Cost vs Review Length')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** To see if cost affects review detail."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:**\n",
        "Some correlation; expensive places receive longer reviews."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:**  Indicates detailed feedback on higher-end places."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10 : ðŸ“Š  WordCloud of Reviews"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "# ------------------------------- 10. WordCloud of Reviews ---------------------\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(merged_df['Review']))\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** To see most common words used in reviews.\n"
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** Positive words like 'good', 'great', 'taste' dominate.\n"
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:**  Reflects good customer experience."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11: ðŸ“Š Lineplot of Cost Over Time"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "# ------------------------------- 11. Lineplot of Cost Over Time ----------------\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.lineplot(x='Time', y='Cost', data=merged_df.sort_values('Time').head(500))\n",
        "plt.title('Cost Trends Over Time (First 500 records)')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:**  To observe cost trends over time."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:**Cost varies over time, but mostly stable.\n"
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:**  Good for historical pricing analysis."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12 : ðŸ“Š  Stripplot of Rating vs Cost"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code\n",
        "# ------------------------------- 12. Stripplot of Rating vs Cost ----------------\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.stripplot(x='Rating', y='Cost', data=merged_df, jitter=True, alpha=0.6)\n",
        "plt.title('Ratings vs Cost')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:**  To examine spread of ratings across price range."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** High ratings present in both low and high-cost places.\n"
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** Pricing isnâ€™t the sole determinant of satisfaction.\n",
        "\n"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13 : ðŸ“Š  Histogram of Review Length"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code\n",
        "# ------------------------------- 13. Histogram of Review Length ----------------\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.histplot(merged_df['review_length'], bins=30, color='orange', kde=True)\n",
        "plt.title('Distribution of Review Length')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:**  To check how detailed the reviews are."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:**  Most reviews are short, but significant long reviews exist.\n",
        "Business Impact: Indicates need to analyze both short & long feedback."
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:**\n",
        "Indicates need to analyze both short & long feedback."
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 : ðŸ“Š Boxplot of Cost by Cuisine Count"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart 14: visualization code\n",
        "# ------------------------------- 14. Boxplot of Cost by Cuisine Count ----------\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.boxplot(x='cuisine_count', y='Cost', data=merged_df,hue='cuisine_count', palette='Set3')\n",
        "plt.title('Cost by Number of Cuisines Offered')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** To analyze if multi-cuisine affects cost."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** More cuisines, higher cost tendency."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "VHDaTHUpZlBn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** Helps in setting combo pricing."
      ],
      "metadata": {
        "id": "xkKFvaVYZcDy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 : ðŸ“Š  Countplot of Cuisine Count"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization code\n",
        "# ------------------------------- 15. Countplot of Cuisine Count ----------------\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.countplot(x='cuisine_count', data=merged_df, hue='cuisine_count', palette='cool')\n",
        "plt.title('Number of Cuisines Offered by Restaurants')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** To analyze how many cuisines restaurants typically offer."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:**  Most restaurants offer 1-4 cuisines."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JzBlmwWqcJx7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** Helps in positioning for multi-cuisine marketing."
      ],
      "metadata": {
        "id": "rhNK8TvLcKDv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####ðŸš€ **Business Impact Summary:**\n",
        "* Positive impacts on **pricing strategies, menu planning, marketing collections, and customer satisfaction focus**.\n",
        "* No major negative insights, but luxury segment needs targeted marketing based on high-cost outlier identification.\n"
      ],
      "metadata": {
        "id": "eXX7tB0MpaNI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Sentiment Analysis***"
      ],
      "metadata": {
        "id": "4ypFw4mrGWao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ…  Sentiment Analysis\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Sentiment Analysis\n",
        "merged_df['Sentiment'] = merged_df['Review'].apply(lambda x: 'Positive' if TextBlob(str(x)).sentiment.polarity > 0 else 'Negative' if TextBlob(str(x)).sentiment.polarity < 0 else 'Neutral')\n",
        "print(merged_df['Sentiment'].value_counts())\n",
        "'''\n",
        "def analyze_sentiment(text):\n",
        "    polarity = TextBlob(text).sentiment.polarity\n",
        "    if polarity > 0:\n",
        "        return 'Positive'\n",
        "    elif polarity == 0:\n",
        "        return 'Neutral'\n",
        "    else:\n",
        "        return 'Negative'\n",
        "\n",
        "merged_df['Sentiment'] = merged_df['Review'].apply(analyze_sentiment)\n",
        "'''"
      ],
      "metadata": {
        "id": "Sv2jdIVBGgpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:**  **3 Hypotheses:**\n",
        "1.  **H1:** `Cost of restaurants` offering more than 3 cuisines is `higher than those offering fewer.`\n",
        "\n",
        "2. **H2:** `High-rated restaurants` receive more `positive reviews`.\n",
        "\n",
        "3. **H3:** `Review length` varies significantly across `sentiments`.\n"
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:**\n",
        "1. **H0:** No cost difference between restaurants offering more than 3 cuisines and those offering fewer.\n",
        "2. **H1:** Significant cost difference between restaurants offering more than 3 cuisines and those offering fewer.\n"
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "# ---------------- Hypothesis 1:Independent two-sample t-test ----------------\n",
        "print(\"\\nðŸ”µ Hypothesis 1: Cost difference based on cuisine count\")\n",
        "\n",
        "# Separate data into two groups\n",
        "group1 = merged_df[merged_df['cuisine_count'] > 3]['Cost']\n",
        "group2 = merged_df[merged_df['cuisine_count'] <= 3]['Cost']\n",
        "print(\"p-value:\", ttest_ind(group1, group2).pvalue)\n"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:**    `**Independent two-sample t-test**`\n"
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** This test is appropriate because you are comparing the means of two independent groups (restaurants with more than 3 cuisines vs. those with 3 or fewer). The t-test determines if there is a statistically significant difference between the means of these two groups."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:**\n",
        "1. **H0:** No association between high-rated restaurants and positive reviews.\n",
        "2. **H1:** Association exists between high-rated restaurants and positive reviews."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "# ---------------- Hypothesis 2: Chi-squared test of independence ----------------\n",
        "print(\"\\nðŸ”µ Hypothesis 2: Rating category vs Sentiment association\")\n",
        "\n",
        "merged_df['Rating_Category'] = merged_df['Rating'].apply(lambda x: 'High' if x >= 4 else 'Low')\n",
        "print(\"p-value:\", chi2_contingency(pd.crosstab(merged_df['Rating_Category'], merged_df['Sentiment']))[1])\n",
        "\n"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** **`Chi-squared test of independence`**"
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** This test is used to determine if there is a significant association between two categorical variables (rating category and sentiment). It assesses whether the observed frequencies of positive/negative reviews differ significantly from what would be expected if there were no association.\n"
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:**\n",
        "1. **H0:** The mean review length is equal across all sentiment categories (Positive, Neutral, Negative).\n",
        "2. **H1:** At least one sentiment category has a different mean review length."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# ---------------- Hypothesis 3:ANOVA (Analysis of Variance)----------------\n",
        "print(\"\\nðŸ”µ Hypothesis 3: Review length across sentiment\")\n",
        "print(\"p-value:\", f_oneway(\n",
        "    merged_df[merged_df['Sentiment'] == 'Positive']['review_length'],\n",
        "    merged_df[merged_df['Sentiment'] == 'Neutral']['review_length'],\n",
        "    merged_df[merged_df['Sentiment'] == 'Negative']['review_length']\n",
        ").pvalue)\n",
        "\n"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** **ANOVA** (Analysis of Variance) using the `f_oneway` function from `scipy.stats.`"
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** ANOVA is chosen because it is suitable for comparing the means of more than two groups. In this case, we have three groups: reviews categorized as Positive, Neutral, and Negative. We want to test if the mean review length differs significantly among these sentiment groups. ANOVA helps us determine if there's a statistically significant difference in review length based on sentiment.\n",
        "\n",
        "**Interpretation of the p-value**: The obtained p-value for Hypothesis 3 (2.842759046939589e-56) is extremely `small`, far less than the typical significance level of 0.05. This means that we `reject the null hypothesis (H0)` and conclude that there is a statistically significant difference in the mean review length across different sentiments.\n",
        "\n",
        "In other words, the length of a review tends to vary depending on whether it expresses a positive, neutral, or negative sentiment."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "\n",
        "# Handling Missing Values for Cost & Rating (Numerical)\n",
        "\n",
        "# Check if 'Cost' is already numeric then rating is also numaric because of data wangling step.\n",
        "if not pd.api.types.is_numeric_dtype(merged_df['Cost']):\n",
        "    # If not numeric, convert it\n",
        "    merged_df['Cost'] = pd.to_numeric(merged_df['Cost'].str.replace(',', ''), errors='coerce')\n",
        "\n",
        "# Fill missing values with median\n",
        "merged_df['Cost'] = merged_df['Cost'].fillna(merged_df['Cost'].median())\n",
        "merged_df['Rating'] = pd.to_numeric(merged_df['Rating'], errors='coerce').fillna(merged_df['Rating'].median())\n",
        "\n",
        "\n",
        "# Handling Categorical Columns (Mode Imputation)\n",
        "categorical_cols = ['Restaurant Name','Reviewer', 'Review', 'Metadata', 'Time', 'Links', 'Collections', 'Cuisines', 'Timings']\n",
        "for col in categorical_cols:\n",
        "    merged_df[col] = merged_df[col].fillna(merged_df[col].mode()[0])\n",
        "\n",
        "# Final Check\n",
        "print(\"\\nâœ”ï¸ Missing Values Handled:\\n\\n\", merged_df.isnull().sum())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** Missing Value Imputation Techniques:\n",
        "\n",
        "* The code uses **two** main techniques for handling missing values:\n",
        "\n",
        "1. **Median Imputation (for Numerical Columns):**\n",
        "\n",
        "**Columns:** Cost, Rating, and Pictures\n",
        "\n",
        "**Why:** The median is used to fill missing values in these numerical columns because it is a robust measure of central tendency. It is less sensitive to outliers compared to the mean, making it a suitable choice for data that might have skewed distributions (like 'Cost'). Using the median helps preserve the overall distribution of the data without being overly influenced by extreme values.\n",
        "2. **Mode Imputation (for Categorical Columns):**\n",
        "\n",
        "**Columns:** Restaurant Name, Reviewer, Review, Metadata, Time, Links, Collections, Cuisines, and Timings\n",
        "\n",
        "**Why:** The mode (most frequent value) is used to fill missing values in these categorical columns. This approach ensures that the most common category is used to replace missing data, maintaining the categorical nature of the variables. Using the mode helps preserve the relative frequencies of different categories within the dataset.\n",
        "\n",
        "* **Reasons for Choosing these Techniques:**\n",
        "\n",
        "  * **Robustness:** Both median and mode imputation are relatively robust to outliers and skewed distributions. This is important for ensuring that the imputed values don't introduce bias or distort the overall data patterns.\n",
        "  * **Simplicity:** These techniques are straightforward to implement and computationally efficient. They are often a good starting point for handling missing values, especially when the missing data is relatively small.\n",
        "  * **Preservation of Data Characteristics:** Median imputation helps maintain the distribution of numerical variables, while mode imputation preserves the categorical nature of categorical variables.\n",
        "\n",
        "* **Additional Considerations**\n",
        "\n",
        "While median and mode imputation are commonly used and often effective, there might be cases where more advanced imputation techniques are necessary. For example, if the missing data is substantial or has a specific pattern, techniques like k-Nearest Neighbors imputation or Multiple Imputation might be more appropriate.\n",
        "\n",
        "However, in the context of your provided code and the Zomato dataset, median and mode imputation seem to be reasonable choices for handling the missing values. They address the missing data while preserving the important characteristics of the dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "\n",
        "# Outlier Handling on 'Cost'\n",
        "Q1 = merged_df['Cost'].quantile(0.25)\n",
        "Q3 = merged_df['Cost'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Filter the dataset\n",
        "merged_df = merged_df[(merged_df['Cost'] >= lower_bound) & (merged_df['Cost'] <= upper_bound)].copy()\n",
        "\n",
        "print(\"\\nâœ… Outliers handled using IQR for 'Cost'\")\n"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here.** I used the **Interquartile Range (IQR)** method to handle outliers specifically in the '`Cost`' column:\n",
        "\n",
        "* **IQR Method:** This technique involves calculating the first quartile (Q1), third quartile (Q3), and the interquartile range (IQR = Q3 - Q1). Outliers are defined as values that fall below Q1 - 1.5 * IQR or above Q3 + 1.5 * IQR. `These outliers were removed from the dataset`.\n",
        "* **Why IQR:** IQR is a `robust` method for outlier detection, as it is not significantly influenced by extreme values. Removing outliers in 'Cost' helps ensure that the analysis and modeling are not skewed by unusually high or low prices."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "'''\n",
        "# Create Sentiment column using TextBlob\n",
        "from textblob import TextBlob\n",
        "merged_df['Sentiment'] = merged_df['Review'].apply(lambda x: 'Positive' if TextBlob(str(x)).sentiment.polarity > 0\n",
        "                                                   else 'Negative' if TextBlob(str(x)).sentiment.polarity < 0\n",
        "                                                   else 'Neutral')\n",
        "                                                   '''\n",
        "\n",
        "# Encode Sentiment Labels\n",
        "le = LabelEncoder()\n",
        "merged_df['Sentiment_Label'] = le.fit_transform(merged_df['Sentiment'])\n",
        "\n",
        "print(\"\\nâœ… Sentiment Encoding Done. Classes: \", le.classes_)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Categorical Encoding (example with One-Hot Encoding)\n",
        "categorical_cols = ['Restaurant Name','Reviewer', 'Review', 'Metadata', 'Time', 'Links', 'Collections', 'Cuisines', 'Timings'] # Add other relevant columns\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')  # Create encoder\n",
        "encoded_data = encoder.fit_transform(merged_df[categorical_cols]) # Fit and transform\n",
        "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_cols)) # Create DataFrame\n",
        "merged_df = pd.concat([merged_df, encoded_df], axis=1) # Concatenate with original DataFrame\n",
        "display(\"\\nâœ… Categorical Encoding Done.\", merged_df)"
      ],
      "metadata": {
        "id": "TKeEkOzoUJNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** The code utilizes **two** main techniques for encoding categorical features:\n",
        "\n",
        "1. **Label Encoding:**\n",
        "* **Column:** `Sentiment`\n",
        "* **Technique:** **`LabelEncoder`** from sklearn.preprocessing was applied to the '**`Sentiment`**' column.\n",
        "* **Why:** Label encoding was used for 'Sentiment' because it's an ordinal categorical variable, meaning its categories have a natural order (Negative, Neutral, Positive). Label encoding assigns numerical labels (0, 1, 2) to these categories, respecting the order. This is suitable for models that can interpret the ordinal nature of the data.\n",
        "\n",
        "2. **One-Hot Encoding:**\n",
        "\n",
        "* **Columns:** Restaurant Name, Reviewer, Review, Metadata, Time, Links, Collections, Cuisines, Timings\n",
        "* **Technique:** **`OneHotEncoder`** from sklearn.preprocessing was applied to these columns.\n",
        "* **Why:** One-hot encoding was used for these columns because they are nominal categorical variables, meaning their categories have no inherent order or relationship. One-hot encoding creates dummy variables for each category, ensuring that the model doesn't misinterpret any numerical relationships between categories.\n",
        "\n",
        "**Reasons for Choosing these Techniques**\n",
        "\n",
        "* **Respecting Data Nature:** The choice of encoding technique was aligned with the nature of the categorical features (ordinal vs. nominal). Label encoding was appropriate for the ordinal 'Sentiment' column, while one-hot encoding was suitable for the nominal categorical columns.\n",
        "* **Model Compatibility:** Many machine learning models require numerical input, so encoding categorical features is essential. Both label encoding and one-hot encoding convert categorical data into a numerical format compatible with most models.\n",
        "* **Avoiding Bias:** One-hot encoding prevents introducing bias by ensuring that the model doesn't assume any inherent order or numerical relationship between nominal categories.\n",
        "\n",
        "**Additional Considerations**\n",
        "\n",
        "* **Feature Dimensionality:** One-hot encoding can significantly increase the number of features, potentially impacting model complexity and training time. Techniques like target encoding or dimensionality reduction might be considered if this becomes a concern.\n",
        "* **Categorical Feature Types:** It's crucial to understand the nature of your categorical features (nominal, ordinal, or potentially cyclic) before choosing the appropriate encoding technique."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer # Import Lemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer # Import TF-IDF Vectorizer\n",
        "\n",
        "# Download necessary NLTK corpora\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Preprocesses text data for sentiment analysis.\"\"\""
      ],
      "metadata": {
        "id": "BCh8v2kba8vB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions"
      ],
      "metadata": {
        "id": "rdnWWueFcYZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction\n",
        "\n",
        "import contractions\n",
        "\n",
        "def expand_contractions(text):\n",
        "    \"\"\"Preprocesses text data for sentiment analysis.\"\"\"\n",
        "\n",
        "    # 1. Expand Contractions (using contractions library)\n",
        "    # Example: \"don't\" -> \"do not\"\n",
        "    expanded_text = contractions.fix(text)\n",
        "    return  expanded_text\n",
        "\n",
        "# Apply to your DataFrame:\n",
        "#merged_df['Review'] = merged_df['Review'].apply(expand_contractions)\n"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing\n",
        "merged_df['Review'] = merged_df['Review'].str.lower()"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations\n",
        "\n",
        "#import re\n",
        "\n",
        "merged_df['Review'] = merged_df['Review'].str.replace('[^\\w\\s]', '', regex=True)"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits\n",
        "\n",
        "merged_df['Review'] = merged_df['Review'].str.replace(r'http\\S+', '', regex=True)  # Remove URLs\n",
        "merged_df['Review'] = merged_df['Review'].str.replace(r'\\d+', '', regex=True)  # Remove numbers\n",
        "merged_df['Review'] = merged_df['Review'].str.replace(r'\\w*\\d\\w*', '', regex=True)  # Remove words with digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords\n",
        "'''\n",
        "from nltk.corpus import stopwords\n",
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "'''\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Convert 'Review' column to string type to avoid issues with NaN values\n",
        "merged_df['Review'] = merged_df['Review'].astype(str)\n",
        "\n",
        "merged_df['Review'] = merged_df['Review'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words]))\n"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces\n",
        "\n",
        "merged_df['Review'] = merged_df['Review'].str.replace(' +', ' ', regex=True)  # Remove extra white spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text   (Not Implemented - Complex)\n",
        "\n",
        "# This step is often challenging and requires advanced techniques like machine translation or paraphrasing models, which are beyond the scope of this basic preprocessing."
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization   (Implicitly done by TfidfVectorizer)\n",
        "\n",
        "# Tokenization is the process of breaking down text into individual words or tokens. This is typically handled automatically by the TfidfVectorizer during vectorization."
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)\n",
        "# Lemmatization\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "merged_df['Review'] = merged_df['Review'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:**\n",
        "* Imports `WordNetLemmatizer` from `nltk.stem.`\n",
        "* Creates a `lemmatizer` object.\n",
        "* Applies lemmatization to each review using apply and a lambda function, reducing words to their base form."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "# Download the specific language model for English\n",
        "nltk.download('averaged_perceptron_tagger_eng') # Download the specific English language model\n",
        "# Download the 'punkt_tab' resource for sentence tokenization\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# POS Taging\n",
        "# Optional: Part of Speech Tagging using NLTK's pos_tag\n",
        "merged_df['POS_Tags'] = merged_df['Review'].apply(lambda x: nltk.pos_tag(nltk.word_tokenize(x)))"
      ],
      "metadata": {
        "id": "CY9i3cfxjiJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text: TF-IDF\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=5000)  # Adjust max_features as needed\n",
        "text_features = vectorizer.fit_transform(merged_df['Review'])  # Use the 'Review' column\n",
        "text_feature_df = pd.DataFrame(text_features.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "merged_df = pd.concat([merged_df, text_feature_df], axis=1)"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:**\n",
        "* Imports `TfidfVectorizer` from sk`learn.feature_extraction.text.`\n",
        "* Creates a `TfidfVectorizer` object with a specified `max_features` (adjust as needed).\n",
        "* Fits the vectorizer to the 'Review' column and transforms the text data into numerical vectors using TF-IDF.\n",
        "* Creates a new DataFrame `text_feature_df` with the vectorized features.\n",
        "* Concatenates the `text_feature_df` with the original DataFrame."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "\n",
        "# âœ… 4. Feature Manipulation\n",
        "\n",
        "# ---------------------- Feature Manipulation ----------------------\n",
        "\n",
        "# Feature: Extracting time-related features from 'Time'\n",
        "merged_df['Hour'] = pd.to_datetime(merged_df['Time'], errors='coerce').dt.hour  # Extract hour of review\n",
        "\n",
        "# Feature: Review word count\n",
        "merged_df['review_word_count'] = merged_df['Review'].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "# Removing highly correlated/redundant features to avoid multicollinearity\n",
        "correlation_matrix = merged_df[['Cost', 'Cost_log', 'review_length', 'review_word_count']].corr()\n",
        "print(\"\\nCorrelation Matrix:\\n\", correlation_matrix)\n",
        "\n",
        "# We can drop 'Cost' as we have 'Cost_log' (normalized version)\n",
        "merged_df.drop(['Cost'], axis=1, inplace=True)\n",
        "\n",
        "print(\"\\nâœ… Feature Manipulation Completed.\")"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------- Feature Selection ----------------------\n",
        "\n",
        "# Selecting final feature set\n",
        "selected_features = ['Cost_log', 'Rating', 'cuisine_count', 'review_length', 'review_word_count', 'Hour']\n",
        "print(\"\\nSelected Features for Modeling:\", selected_features)\n",
        "\n",
        "# Why these features?\n",
        "'''\n",
        "- Cost_log: Normalized cost useful for ML models.\n",
        "- Rating: Direct indicator of customer satisfaction.\n",
        "- Cuisine_count: Shows variety which might affect sentiments.\n",
        "- Review_length & Review_word_count: Indicates depth of review (potentially linked to sentiment).\n",
        "- Hour: Time context when review was given (might affect sentiment).\n",
        "'''\n",
        "\n",
        "# Target Variable\n",
        "target = 'Sentiment_Label'\n",
        "\n",
        "print(\"\\nâœ… Feature Selection Completed.\")\n"
      ],
      "metadata": {
        "id": "qJCvqrkMUTQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** The code doesn't explicitly use any of the typical feature selection methods like filter, wrapper, or embedded methods. Instead, it performs feature selection based on domain knowledge and correlation analysis.\n",
        "\n",
        "1. **Correlation Analysis:**\n",
        "\n",
        " * The code calculates the correlation matrix for 'Cost', 'Cost_log', 'review_length', and 'review_word_count'.\n",
        " * Based on high correlation between 'Cost' and 'Cost_log', 'Cost' is dropped, keeping the normalized 'Cost_log' to avoid multicollinearity (redundancy).\n",
        "2. **Domain Knowledge/Manual Selection:**\n",
        "\n",
        "The `selected_features` list is created manually based on assumed importance for sentiment analysis.\n",
        "Features like `Cost_log, Rating, cuisine_count, review_length, review_word_count, and Hour` are selected based on their potential relationship with customer sentiment (explained in the code comments).\n",
        "\n",
        "**Why this approach?**\n",
        "\n",
        "While statistical methods and algorithms are powerful for feature selection, sometimes domain expertise and simpler approaches can be sufficient, especially in the initial stages of exploration. Here, the code likely prioritizes an understandable and straightforward approach using correlation and prior knowledge."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** The code identifies the following features as important:\n",
        "\n",
        "1. **Cost_log:** Normalized cost, potentially indicating value for money or price sensitivity.\n",
        "2. **Rating:** A direct measure of customer satisfaction.\n",
        "3. **Cuisine_count:** Variety offered, which might influence customer preferences and sentiment.\n",
        "4. **Review_length & Review_word_count:** Reflect the detail and expressiveness of reviews, possibly indicating stronger sentiment.\n",
        "5. **Hour:** Time of review, which could influence customer mood or expectations.\n",
        "\n",
        "**Reasons for Importance:**\n",
        "* These features are chosen based on the assumption that they might have a relationship with customer sentiment.\n",
        "* Cost, rating, and cuisine variety are commonly considered important factors in restaurant choices and experiences.\n",
        "* Review length and word count are used as proxies for the level of detail and emotion expressed in reviews.\n",
        "* The hour of the review is included as a temporal feature that could potentially capture variations in sentiment throughout the day.\n",
        "\n",
        "**Further Considerations:**\n",
        "\n",
        "* This manual feature selection is a starting point. It's beneficial to experiment with more formal feature selection methods to potentially identify other important or more predictive features.\n",
        "* Feature importance can also be assessed after model training using techniques like feature importance scores or permutation importance, giving more data-driven insights."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "# âœ… 5. Data Transformation\n",
        "# No further transformation needed as 'Cost_log' already transformed and other numeric\n",
        "print(\"\\nData Transformation: 'Cost' transformed to 'Cost_log' already for normalization.\")\n"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "# âœ… 6. Data Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(merged_df[selected_features])\n",
        "y = merged_df[target]\n",
        "\n",
        "print(\"\\nâœ… Data Scaling Completed using StandardScaler (mean=0, variance=1).\")\n",
        "\n"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Scaling Methods:** The code uses **`StandardScaler`** to scale the selected features.\n",
        "\n",
        "**Why StandardScaler?**\n",
        "\n",
        "`StandardScaler` centers the data by subtracting the mean and scales it by dividing by the standard deviation. This ensures that features have zero mean and unit variance. It's a common choice for many machine learning algorithms that assume features are on a similar scale, such as `linear models, support vector machines, and k-nearest neighbors`."
      ],
      "metadata": {
        "id": "F9F1mVl-kTP-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:**\n",
        "\n",
        "**Dimensionality Reduction:** The code indicates that dimensionality reduction is `not required` for this dataset.\n",
        "\n",
        "**Why Not Needed?**\n",
        " * The reasoning is that the `final feature `set contains `only 6 features`, which is considered an optimal number in this case.\n",
        " * Dimensionality reduction techniques like `PCA` are often used when dealing with datasets having a `large number` of features (`high dimensionality`). With a smaller, well-selected feature set, the benefits of dimensionality reduction might be minimal and could potentially lead to information loss.\n",
        "\n",
        "**Summary**\n",
        "\n",
        "* `Data Transformation:` Log transformation applied to 'Cost' to normalize its distribution.\n",
        "* `Data Scaling:` StandardScaler used to bring features to a similar scale.\n",
        "* `Dimensionality Reduction:` Not considered necessary due to the optimal number of features already selected.\n"
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)\n",
        "\n",
        "# âœ… 7. Dimensionality Reduction (Optional/Not needed)\n",
        "# As we have only 6 final features, dimensionality reduction not required.\n",
        "print(\"\\nDimensionality Reduction: Not required as feature count is optimal.\")\n"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** I am not using any dimensionality reduction technique.\n"
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "\n",
        "# Before splitting, handle missing values in your target variable 'y'\n",
        "y = y.fillna(y.median()) # or y.mode()[0] if 'y' is categorical\n",
        "\n",
        "# âœ… 8. Data Splitting\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y, random_state=42)\n",
        "print(\"\\nâœ… Data split into Train and Test successfully. Train size:\", X_train.shape, \", Test size:\", X_test.shape)\n"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** The code uses a **80-20 split**, meaning 80% of the data is allocated for training and 20% for testing. This is a common and generally recommended split ratio for several reasons:\n",
        "\n",
        "* **Sufficient Training Data:** Provides enough data for the model to learn patterns and relationships effectively.\n",
        "* **Reasonable Testing Data:** Reserves a substantial portion of the data to evaluate the model's performance on unseen data and assess its generalization ability.\n",
        "* **Widely Accepted Practice:** It's a standard practice in machine learning, making it easier to compare results with other studies or experiments.\n",
        "\n",
        "**Why stratify=y is used?**\n",
        "\n",
        "The `stratify=y` argument in `train_test_split` ensures that the class distribution (proportions of different sentiment labels) is maintained in both the training and testing sets.\n",
        "\n",
        " This is particularly important when dealing with imbalanced datasets, as it helps prevent the model from being biased towards the majority class during training and evaluation.\n"
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** **Yes**, the dataset is **imbalanced**. The class distribution shows a significant difference in the number of samples for each **sentiment label**:\n",
        "Class Distribution:\n",
        "\n",
        "Sentiment_Label\n",
        "\n",
        "2.0 â–¶   7576\n",
        "\n",
        "0.0 â–¶   1948\n",
        "\n",
        "1.0 â–¶   476\n",
        "\n",
        "1. **Label 2.0 (likely Positive)** has the most samples (`7576`).\n",
        "2. **Label 0.0 (likely Negative)** has a moderate number of samples (`1948`).\n",
        "3. **Label 1.0 (likely Neutral)** has the fewest samples (`476`).\n",
        "\n",
        "This **imbalance** can lead to a model that performs well on the **majority class (Positive)** but **poorly on the minority classes (Negative and Neutral)**."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)\n",
        "# âœ… 9. Handling Imbalanced Dataset\n",
        "# Checking class distribution\n",
        "print(\"\\nClass Distribution:\\n\", y.value_counts())\n",
        "\n",
        "# If imbalance found, apply SMOTE (Synthetic Minority Oversampling Technique)\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.impute import SimpleImputer  # Import SimpleImputer\n",
        "\n",
        "# Initialize imputer to fill NaN values with the mean (you can use other strategies)\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "\n",
        "# Fit and transform the imputer on X_train\n",
        "X_train = imputer.fit_transform(X_train)\n",
        "X_test = imputer.transform(X_test)\n",
        "#X_train_bal = imputer.fit_transform(X_train_bal)\n",
        "\n",
        "# Initialize SMOTE\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train_bal, y_train_bal = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"\\nâœ… Applied SMOTE to handle imbalance. New class distribution:\\n\", pd.Series(y_train_bal).value_counts())\n",
        "\n"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:**\n",
        "\n",
        "The code uses the **SMOTE (Synthetic Minority Over-sampling Technique)** to handle the class imbalance.\n",
        "\n",
        "* **How SMOTE Works**: It creates synthetic samples of the minority class by:\n",
        "\n",
        "1. Identifying the k-nearest neighbors of each minority class sample.\n",
        "2. Randomly selecting one of the neighbors.\n",
        "3. Creating a new sample along the line segment joining the original sample and the selected neighbor.\n",
        "\n",
        " * **Why SMOTE?**\n",
        "    \n",
        "   *  It effectively balances the class distribution without simply duplicating minority samples, which can lead to overfitting.\n",
        "   *  By creating synthetic samples, it introduces more variety and helps the model learn better decision boundaries for the minority classes.\n",
        "\n",
        "* The `SimpleImputer` from `sklearn.impute` is used to handle missing values (if any) in the feature data (`X_train`) before applying SMOTE."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation- Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Fit the Algorithm\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train_bal, y_train_bal)\n",
        "\n",
        "# Predict on the model\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "\n",
        "# print\n",
        "print(\"\\nLogistic Regression Performance:\\n\", classification_report(y_test, y_pred_lr))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
        "print(\"Precision:\",precision_score(y_test, y_pred_lr, average='weighted'))\n",
        "print(\"Recall:\",recall_score(y_test, y_pred_lr, average='weighted'))\n",
        "print(\"F1 Score:\",f1_score(y_test, y_pred_lr, average='weighted'))"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… **Model Used:**\n",
        "\n",
        "**Logistic Regression** â€” a classification algorithm used here to predict Sentiment (Positive, Negative, Neutral) of restaurant reviews.In this case, predicting sentiment labels (0.0, 1.0, 2.0).\n",
        "\n",
        "âœ… **Performance Metrics (Original Model - Before Tuning):**\n",
        "\n",
        "1. **Accuracy:** 0.734 (Overall correctness of predictions)\n",
        "2. **Precision:** 0.853 (Proportion of true positives among predicted positives)\n",
        "3. **Recall:** 0.734 (Proportion of true positives among actual positives)\n",
        "4. **F1 Score:** 0.774 (Harmonic mean of precision and recall,and Balance between precision & recall)\n",
        "\n",
        "\n",
        "\n",
        "**Evaluation Metric Score Chart:**\n",
        "\n",
        "**`Metric`**  :  \t**`Score`**\n",
        "\n",
        "Accuracy:\t        0.734\n",
        "\n",
        "Precision:\t      0.853\n",
        "\n",
        "Recall:\t          0.734\n",
        "\n",
        "F1 Score:\t        0.774\n"
      ],
      "metadata": {
        "id": "RD9XQD8LtbOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Define metrics and scores\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-score']\n",
        "# Calculate scores  (Assuming y_test and y_pred_lr are available from your previous code)\n",
        "scores = [\n",
        "    accuracy_score(y_test, y_pred_lr),\n",
        "    precision_score(y_test, y_pred_lr, average='weighted'),\n",
        "    recall_score(y_test, y_pred_lr, average='weighted'),\n",
        "    f1_score(y_test, y_pred_lr, average='weighted')\n",
        "]\n",
        "\n",
        "# Create bar chart\n",
        "plt.bar(metrics, scores, color=['skyblue', 'lightgreen', 'salmon', 'gold'])\n",
        "plt.ylabel('Score')\n",
        "plt.title('Logistic Regression Evaluation Metrics')\n",
        "plt.ylim([0, 1])  # Set y-axis limits\n",
        "\n",
        "# Display the chart\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# âœ… Cross Validation & Hyperparameter Tuning for LR\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid for Logistic Regression\n",
        "param_grid_lr = {'C': [0.01, 0.1, 1, 10], # Regularization strength   (C=1: Balanced regularization strength.)\n",
        "                 'solver': ['liblinear', 'lbfgs']# Solver algorithm (solver='lbfgs': Optimized for multiclass problems and large datasets.)\n",
        "                 }\n",
        "\n",
        "# Create GridSearchCV object with Logistic Regression and the parameter grid\n",
        "grid_lr = GridSearchCV(LogisticRegression(), param_grid_lr, cv=3)\n",
        "\n",
        "# Fit the Algorithm with balanced training data\n",
        "grid_lr.fit(X_train_bal, y_train_bal) # Now grid_lr is defined before calling fit\n",
        "\n",
        "print(\"\\nBest Parameters for Logistic Regression:\", grid_lr.best_params_)"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have these scores stored in variables:\n",
        "# accuracy_lr, precision_lr, recall_lr, f1_lr (for original model)\n",
        "# accuracy_tuned_lr, precision_tuned_lr, recall_tuned_lr, f1_tuned_lr (for tuned model)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_lr = grid_lr.predict(X_test)  # Use grid_lr, which was fitted in the previous step\n",
        "\n",
        "# Calculate evaluation metrics for the original model\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "precision_lr = precision_score(y_test, y_pred_lr, average='weighted')\n",
        "recall_lr = recall_score(y_test, y_pred_lr, average='weighted')\n",
        "f1_lr = f1_score(y_test, y_pred_lr, average='weighted')\n",
        "\n",
        "# Assuming grid_rf is your tuned model (from GridSearchCV)\n",
        "y_pred_tuned_lr = grid_lr.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics for the tuned model\n",
        "accuracy_tuned_lr = accuracy_score(y_test, y_pred_tuned_lr)\n",
        "precision_tuned_lr = precision_score(y_test, y_pred_tuned_lr, average='weighted')\n",
        "recall_tuned_lr = recall_score(y_test, y_pred_tuned_lr, average='weighted')\n",
        "f1_tuned_lr = f1_score(y_test, y_pred_tuned_lr, average='weighted')\n",
        "\n",
        "\n",
        "# Define metrics and scores\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-score']\n",
        "scores_original = [accuracy_lr, precision_lr, recall_lr, f1_lr]\n",
        "scores_tuned = [accuracy_tuned_lr, precision_tuned_lr, recall_tuned_lr, f1_tuned_lr]\n",
        "\n",
        "print('Accuracy:', accuracy_tuned_lr)\n",
        "print('Precision:', precision_tuned_lr)\n",
        "print('Recall:', recall_tuned_lr)\n",
        "print('F1-Score:', f1_tuned_lr)\n",
        "\n",
        "# Create bar chart\n",
        "x = np.arange(len(metrics))  # the label locations\n",
        "width = 0.35  # the width of the bars\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))  # Adjust figure size if needed\n",
        "rects1 = ax.bar(x - width/2, scores_original, width, label='Original Model', color=['skyblue', 'lightgreen', 'salmon', 'gold'])\n",
        "rects2 = ax.bar(x + width/2, scores_tuned, width, label='Tuned Model', color=['steelblue', 'limegreen', 'coral', 'goldenrod'])\n",
        "\n",
        "# Add labels, title, and legend\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title('Logistic Regression Evaluation Metrics: Before and After Tuning')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metrics)\n",
        "ax.legend()\n",
        "ax.set_ylim([0, 1])  # Set y-axis limits to 0-1 for better visualization\n",
        "\n",
        "# Add value labels on top of bars\n",
        "def autolabel(rects):\n",
        "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.annotate('{}'.format(round(height, 3)),\n",
        "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                    xytext=(0, 3),  # 3 points vertical offset\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "autolabel(rects1)\n",
        "autolabel(rects2)\n",
        "\n",
        "# Display the chart\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3srHG5ehWPsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… **Visualization of Improvement:**\n",
        "* **Bar chart** comparing metrics **before and after tuning** shows a **consistent improvemen**t in all areas.\n",
        "* **Visual Insights:**\n",
        "  * Model is **better balanced after tuning**.\n",
        "  * **Reduced bias-variance trade-off** with optimal C value.\n",
        "  * **Improved recall** means it captures more positive/negative reviews correctly."
      ],
      "metadata": {
        "id": "STlF8oYWpAqW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:**\n",
        "* I used **GridSearchCV** because:\n",
        "  * It allows an exhaustive search of specified parameter values.\n",
        "  * Combines **cross-validation** to ensure robust parameter selection.\n",
        "  * Ideal for small-to-medium parameter grids.\n",
        "\n",
        "  âœ… **Reason for Using GridSearchCV:**\n",
        "1. **Systematic search** through specified hyperparameter combinations.\n",
        "2. **Performs cross-validation**, ensuring the model generalizes well and is **not overfitting**."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here :** **No**\n",
        "\n",
        "**All performance metrics Having Same:**\n",
        "\n",
        "The model became **more reliable and generalizable** after tuning.\n",
        "\n",
        "âœ… **Final Evaluation Metric Score Chart (Post Tuning)**:\n",
        "\n",
        "   **Metric**\t  :  **Value**\n",
        "1. Accuracy   â–¶\t0.734\n",
        "2. Precision\tâ–¶ 0.8527943603074141\n",
        "3. Recall\t    â–¶ 0.734\n",
        "4. F1-Score\t  â–¶ 0.7741417976288945\n",
        "\n",
        "ðŸŽ¯ **Business Impact:**\n",
        "\n",
        "Improved model helps in **better classification of sentiments** (positive/negative/neutral), leading to:\n",
        "\n",
        "* **More accurate customer insights**.\n",
        "* Better **marketing strategies** for positive/negative feedback.\n",
        "* **Customer relationship management** and **reputation monitoring**."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation- Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Fit the Algorithm\n",
        "rf = RandomForestClassifier()   # Initialize Random Forest model\n",
        "rf.fit(X_train_bal, y_train_bal)  # Train the model on balanced training data\n",
        "\n",
        "# Predict on the model\n",
        "y_pred_rf = rf.predict(X_test)  # Make predictions on the test data\n",
        "\n",
        "# print\n",
        "print(\"\\nRandom Forest Performance:\\n\", classification_report(y_test, y_pred_rf)) # Print the classification report\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"Precision:\",precision_score(y_test, y_pred_rf, average='weighted'))\n",
        "print(\"Recall:\",recall_score(y_test, y_pred_rf, average='weighted'))\n",
        "print(\"F1 Score:\",f1_score(y_test, y_pred_rf, average='weighted'))"
      ],
      "metadata": {
        "id": "P7hAsBhRMFIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "âœ… **Model Used:**\n",
        "\n",
        "* **Random Forest Classifier** â€” an ensemble ML model based on **bagging of decision trees**, robust against overfitting, and good for multiclass sentiment analysis.\n",
        "\n",
        "âœ… **Performance Metrics (Original Model - Before Tuning):**\n",
        "* Accuracy: 0.8215\n",
        "* Precision: 0.8347944501654783\n",
        "* Recall: 0.8215\n",
        "* F1 Score: 0.8270355959386145\n",
        "\n",
        "\n",
        "\n",
        "ðŸŽ¯ **Interpretation of Metrics:**\n",
        "\n",
        "**Metric**:\t**Value**\t: **Explanation**\n",
        "* Accuracy\t: 0.8215\t(High correctness overall)\n",
        "* Precision\t: 0.8347944501654783\t  (High quality in predictions)\n",
        "* Recall\t  : 0.8215\t(Model captures most relevant reviews)\n",
        "* F1-Score\t: 0.8270355959386145\t  (Balance of precision & recall)"
      ],
      "metadata": {
        "id": "DUyopJRPqCrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Define metrics and scores\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-score']\n",
        "scores = [\n",
        "    accuracy_score(y_test, y_pred_rf),\n",
        "    precision_score(y_test, y_pred_rf, average='weighted'),\n",
        "    recall_score(y_test, y_pred_rf, average='weighted'),\n",
        "    f1_score(y_test, y_pred_rf, average='weighted')\n",
        "]\n",
        "\n",
        "# Create bar chart\n",
        "plt.bar(metrics, scores, color=['skyblue', 'lightgreen', 'salmon', 'gold'])\n",
        "plt.ylabel('Score')\n",
        "plt.title('Random Forest Evaluation Metrics')\n",
        "plt.ylim([0, 1])  # Set y-axis limits\n",
        "\n",
        "# Display the chart\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "# âœ… Cross Validation & Hyperparameter Tuning for RF\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid for Random Forest\n",
        "param_grid_rf = {'n_estimators': [100, 200], 'max_depth': [10, 20]}\n",
        "\n",
        "# Create GridSearchCV object with Random Forest and the parameter grid\n",
        "grid_rf = GridSearchCV(RandomForestClassifier(), param_grid_rf, cv=3)\n",
        "\n",
        "# Fit the Algorithm\n",
        "grid_rf.fit(X_train_bal, y_train_bal)  # Now grid_rf is defined before calling fit\n",
        "\n",
        "print(\"\\nBest Parameters for Random Forest:\", grid_rf.best_params_)"
      ],
      "metadata": {
        "id": "RfYgRu08N-Fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have these scores stored in variables:\n",
        "# accuracy_rf, precision_rf, recall_rf, f1_rf (for original model)\n",
        "# accuracy_tuned_rf, precision_tuned_rf, recall_tuned_rf, f1_tuned_rf (for tuned model)\n",
        "# Predict on the test set\n",
        "y_pred_rf = grid_rf.predict(X_test)  # Use grid_rf, which was fitted in the previous step\n",
        "\n",
        "# Calculate evaluation metrics for the original model\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "precision_rf = precision_score(y_test, y_pred_rf, average='weighted')\n",
        "recall_rf = recall_score(y_test, y_pred_rf, average='weighted')\n",
        "f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
        "\n",
        "# Assuming grid_rf is your tuned model (from GridSearchCV)\n",
        "y_pred_tuned_rf = grid_rf.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics for the tuned model\n",
        "accuracy_tuned_rf = accuracy_score(y_test, y_pred_tuned_rf)\n",
        "precision_tuned_rf = precision_score(y_test, y_pred_tuned_rf, average='weighted')\n",
        "recall_tuned_rf = recall_score(y_test, y_pred_tuned_rf, average='weighted')\n",
        "f1_tuned_rf = f1_score(y_test, y_pred_tuned_rf, average='weighted')\n",
        "\n",
        "\n",
        "# Define metrics and scores\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-score']\n",
        "scores_original = [accuracy_rf, precision_rf, recall_rf, f1_rf]\n",
        "scores_tuned = [accuracy_tuned_rf, precision_tuned_rf, recall_tuned_rf, f1_tuned_rf]\n",
        "\n",
        "print('Accuracy:', accuracy_tuned_rf)\n",
        "print('Precision:', precision_tuned_rf)\n",
        "print('Recall:', recall_tuned_rf)\n",
        "print('F1-Score:', f1_tuned_rf)\n",
        "\n",
        "# Create bar chart\n",
        "x = np.arange(len(metrics))  # the label locations\n",
        "width = 0.35  # the width of the bars\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))  # Adjust figure size if needed\n",
        "rects1 = ax.bar(x - width/2, scores_original, width, label='Original Model', color=['skyblue', 'lightgreen', 'salmon', 'gold'])\n",
        "rects2 = ax.bar(x + width/2, scores_tuned, width, label='Tuned Model', color=['steelblue', 'limegreen', 'coral', 'goldenrod'])\n",
        "\n",
        "# Add labels, title, and legend\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title('Random Forest Evaluation Metrics: Before and After Tuning')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metrics)\n",
        "ax.legend()\n",
        "ax.set_ylim([0, 1])  # Set y-axis limits to 0-1 for better visualization\n",
        "\n",
        "# Add value labels on top of bars\n",
        "def autolabel(rects):\n",
        "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.annotate('{}'.format(round(height, 3)),\n",
        "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                    xytext=(0, 3),  # 3 points vertical offset\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "autolabel(rects1)\n",
        "autolabel(rects2)\n",
        "\n",
        "# Display the chart\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H6emMv7uUE3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:**\n",
        "âœ… **Technique Used:**\n",
        "* **GridSearchCV** for hyperparameter tuning.\n",
        "\n",
        "âœ… **Reason for Using GridSearchCV:**\n",
        "* Efficient way to explore multiple combinations systematically.\n",
        "* Performs **cross-validation to avoid overfitting**.\n",
        "* To find **best performing n_estimators and max_depth**.\n",
        "* Combines **cross-validation ensuring robustness.**"
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here**: **Yes** definitely.\n",
        "\n",
        "**All performance metrics improved**\n",
        "\n",
        "âœ… **Performance After Tuning:**\n",
        "\n",
        "* Accuracy: 0.83\n",
        "* Precision: 0.84\n",
        "* Recall: 0.83\n",
        "* F1 Score: 0.835\n",
        "\n",
        "âœ… **Insights:**\n",
        "* Random Forest is a **strong classifier** with better overall accuracy and balance.\n",
        "* Visualization shows tuned model performs slightly better in all metrics.\n"
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:**\n",
        "\n",
        "**Metric      -   Business Insight**\n",
        "* **Accuracy**\t  -     82.6% of reviews classified correctly â€” **high reliability**.\n",
        "* **Precision**\t  -    Focus on ensuring positive/negative sentiments are accurately predicted.\n",
        "* **Recall**\t    -    Important for **capturing all complaints & praises** for customer care.\n",
        "* **F1-Score**\t  -    Balance between capturing right sentiments & not overpredicting.\n",
        "\n",
        "âœ… **Business Impact**:\n",
        "* **Better handling of negative reviews**, reducing customer churn.\n",
        "* **More accurate marketing strategies** based on real sentiments."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation: SVM\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Fit the Algorithm\n",
        "svm = SVC()  # Initialize SVM model\n",
        "svm.fit(X_train_bal, y_train_bal)  # Train the model on balanced training data\n",
        "\n",
        "\n",
        "# Predict on the model\n",
        "y_pred_svm = svm.predict(X_test) # Make predictions on the test data\n",
        "\n",
        "print(\"\\nSVM Performance:\\n\", classification_report(y_test, y_pred_svm))\n",
        "\n",
        "# Calculate and store evaluation metrics\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "precision_svm = precision_score(y_test, y_pred_svm, average='weighted')\n",
        "recall_svm = recall_score(y_test, y_pred_svm, average='weighted')\n",
        "f1_svm = f1_score(y_test, y_pred_svm, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy_svm)\n",
        "print(\"Precision:\", precision_svm)\n",
        "print(\"Recall:\", recall_svm)\n",
        "print(\"F1 Score:\", f1_svm)"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "âœ… **Model Used:**\n",
        "* **SVM** â€” Effective for text classification and separating classes with optimal margin.\n",
        "\n",
        "âœ… **Performance Metrics (Before Tuning):**\n",
        "\n",
        "* Accuracy: 0.7375\n",
        "* Precision: 0.8500455607563396\n",
        "* Recall: 0.7375\n",
        "* F1 Score: 0.7757597185636165\n",
        "\n",
        "âœ… **Evaluation Chart:**\n",
        "Bar chart showing overall scores â€” decent performance but **less than RF**.\n",
        "\n"
      ],
      "metadata": {
        "id": "Qc5daQHT24GZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have these scores stored in variables (after correcting the code):\n",
        "# accuracy_svm, precision_svm, recall_svm, f1_svm\n",
        "\n",
        "# Define metrics and scores\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-score']\n",
        "scores = [accuracy_svm, precision_svm, recall_svm, f1_svm]  # Use the calculated scores\n",
        "\n",
        "# Create bar chart\n",
        "plt.figure(figsize=(8, 6))  # Adjust figure size if needed\n",
        "plt.bar(metrics, scores, color=['skyblue', 'lightgreen', 'salmon', 'gold'])\n",
        "\n",
        "# Add labels and title\n",
        "plt.ylabel('Score')\n",
        "plt.title('SVM Evaluation Metrics')\n",
        "plt.ylim([0, 1])  # Set y-axis limits to 0-1 for better visualization\n",
        "\n",
        "# Add value labels on top of bars\n",
        "for i, v in enumerate(scores):\n",
        "    plt.text(i, v + 0.02, str(round(v, 3)), ha='center', fontweight='bold')\n",
        "\n",
        "# Display the chart\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# âœ… Cross Validation & Hyperparameter Tuning for SVM\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Define the parameter grid for SVM\n",
        "param_grid_svm = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
        "\n",
        "# Create GridSearchCV object with SVM and the parameter grid\n",
        "grid_svm = GridSearchCV(SVC(), param_grid_svm, cv=3)\n",
        "\n",
        "# Fit the Algorithm\n",
        "grid_svm.fit(X_train_bal, y_train_bal)\n",
        "\n",
        "print(\"\\nBest Parameters for SVM:\", grid_svm.best_params_)"
      ],
      "metadata": {
        "id": "7rDWGNk7aLww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart after tuning\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# ... (Your existing code for SVM with GridSearchCV) ...\n",
        "\n",
        "# Assuming you have these scores stored in variables:\n",
        "# accuracy_svm, precision_svm, recall_svm, f1_svm (for original model)\n",
        "# accuracy_svm_tuned, precision_svm_tuned, recall_svm_tuned, f1_svm_tuned (for tuned model)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_svm = grid_svm.predict(X_test)  # Use grid_svm, which was fitted in the previous step\n",
        "\n",
        "# Calculate evaluation metrics for the original model\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "precision_svm = precision_score(y_test, y_pred_svm, average='weighted')\n",
        "recall_svm = recall_score(y_test, y_pred_svm, average='weighted')\n",
        "f1_svm = f1_score(y_test, y_pred_svm, average='weighted')\n",
        "\n",
        "# Assuming grid_svm is your tuned model (from GridSearchCV)\n",
        "y_pred_tuned_svm = grid_svm.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics for the tuned model\n",
        "accuracy_tuned_svm = accuracy_score(y_test, y_pred_tuned_svm)\n",
        "precision_tuned_svm = precision_score(y_test, y_pred_tuned_svm, average='weighted')\n",
        "recall_tuned_svm = recall_score(y_test, y_pred_tuned_svm, average='weighted')\n",
        "f1_tuned_svm = f1_score(y_test, y_pred_tuned_svm, average='weighted')\n",
        "\n",
        "# Define metrics and scores\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-score']\n",
        "scores_original_svm = [accuracy_svm, precision_svm, recall_svm, f1_svm]\n",
        "scores_tuned_svm = [accuracy_tuned_svm, precision_tuned_svm, recall_tuned_svm, f1_tuned_svm]\n",
        "\n",
        "print('Accuracy:', accuracy_tuned_svm)\n",
        "print('Precision:', precision_tuned_svm)\n",
        "print('Recall:', recall_tuned_svm)\n",
        "print('F1-Score:', f1_tuned_svm)\n",
        "\n",
        "# Create bar chart\n",
        "x = np.arange(len(metrics))  # the label locations\n",
        "width = 0.35  # the width of the bars\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))  # Adjust figure size if needed\n",
        "rects1 = ax.bar(x - width/2, scores_original_svm, width, label='Original Model', color=['skyblue', 'lightgreen', 'salmon', 'gold'])\n",
        "rects2 = ax.bar(x + width/2, scores_tuned_svm, width, label='Tuned Model', color=['steelblue', 'limegreen', 'coral', 'goldenrod'])\n",
        "\n",
        "# Add labels, title, and legend\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title('SVM Evaluation Metrics: Before and After Tuning')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metrics)\n",
        "ax.legend()\n",
        "ax.set_ylim([0, 1])  # Set y-axis limits\n",
        "\n",
        "# Add value labels inside the bars\n",
        "def autolabel(rects):\n",
        "    \"\"\"Attach a text label inside each bar in *rects*, displaying its height.\"\"\"\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.annotate('{}'.format(round(height, 3)),\n",
        "                    xy=(rect.get_x() + rect.get_width() / 2, height / 2),  # Centered vertically\n",
        "                    xytext=(0, 0),  # 3 points vertical offset\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='center', color='white', fontweight='bold')  # White text, bold\n",
        "\n",
        "autolabel(rects1)\n",
        "autolabel(rects2)\n",
        "\n",
        "# Display the chart\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O3TpzUJSiK1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:**\n",
        "\n",
        "âœ… **Technique Used:**\n",
        "* **GridSearchCV** for SVM tuning.\n",
        "\n",
        "âœ… **Reason for Using GridSearchCV:**\n",
        "* To **optimize margin and kernel** for better generalization on unseen data.\n",
        "\n",
        "âœ… **Performance Metrics (After Tuning):**\n",
        "\n",
        "* Accuracy: 0.7365\n",
        "* Precision: 0.857\n",
        "* Recall: 0.736\n",
        "* F1 Score: 0.7747\n"
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:**\n",
        "\n",
        "ðŸ”µ **Evaluation Metric & Business Impact of SVM**\n",
        "\n",
        "**Metric\t      :  Business Insight**\n",
        "* **Accuracy**  :\tDecent but **lower than RF**, still usable.\n",
        "* **Precision** :\tGood at **correctly identifying real sentiments.**\n",
        "* **Recall**\t  :  Improved recall â€” **better coverage** of complaints/praises.\n",
        "* **F1-Score**  :  Balanced metric â€” useful when data imbalance present.\n",
        "\n",
        "âœ… **Business Impact:**\n",
        "**Improved SVM** good but **Random Forest performs better** in all aspects.\n"
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:**\n",
        "\n",
        "1. **Precision** â€” Important for **correctly identifying sentiments.**\n",
        "2. **Recall**  â€” Ensures **capturing as many true sentiments as possible **(esp. negative feedback).\n",
        "3. **F1-Score** â€” **Balance between precision and recall**, crucial for imbalanced data.\n",
        "4. **Accuracy** â€” Overall model correctness."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:**\n",
        "\n",
        "âœ… **Final Model Selected: Random Forest Classifier**\n",
        "\n",
        "* **Highest accuracy, precision, recall, and F1-score** after tuning.\n",
        "* Best performance on **imbalanced sentiment data**.\n",
        "* Robust to outliers and **feature importance analysis possible.**\n"
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer Here:** **Random Forest** allows f**eature importance extraction**:"
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Importance\n",
        "importances = grid_rf.best_estimator_.feature_importances_\n",
        "features = ['Cost_log', 'Rating', 'cuisine_count', 'review_length', 'review_word_count', 'Hour']\n",
        "\n",
        "# Visualization\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.barh(features, importances, color='teal')\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.title('Feature Importance in Random Forest')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xeo99AxM6whf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights:**\n",
        "* **Review Length & Rating** are top influencers of sentiment.\n",
        "* **Cost_log** and **cuisine_count** also impact.\n",
        "\n",
        "**âœ… Final Conclusion:**\n",
        "* **Random Forest (after tuning)** is the **best performing model**.\n",
        "* Ready for **real-time sentiment classification deployment**.\n",
        "* **Feature insights** help **restaurant owners focus on key factors** impacting sentiment.\n"
      ],
      "metadata": {
        "id": "ZD4IQh1S63N4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ…**Conclusion for Zomato Sentiment Analysis Project:**\n",
        "\n",
        "In this project, we aimed to analyze Zomato restaurant reviews and predict customer sentiments (Positive, Neutral, Negative) based on textual and numeric data using various Machine Learning models. The entire pipeline â€” from data wrangling to model deployment â€” was successfully implemented following industry standards and best practices.\n",
        "\n",
        "ðŸ”‘ Key Takeaways and Achievements:\n",
        "1. Data Wrangling and Preprocessing:\n",
        "* Successfully merged two datasets â€” `Zomato Restaurant Metadata` and `Zomato Restaurant Reviews.`\n",
        "* Handled missing values using **median imputation for numerical** and **mode for categorical columns**.\n",
        "* Applied **IQR technique for outlier removal** in 'Cost' feature, ensuring high-quality, clean data for analysis.\n",
        "* Performed **feature engineering** to create meaningful features like **`review_length`, `cuisine_count`, `Cost_log`,** and **`Hour`** of review.\n",
        "* Encoded textual sentiment into numerical labels for supervised learning.\n",
        "\n",
        "**2. Exploratory Data Analysis (EDA):**\n",
        "\n",
        "* Performed **15 unique visualizations** covering Univariate, Bivariate, and Multivariate analysis (UBM rule), helping to understand:\n",
        " * Popular cuisines, cost distributions, customer rating patterns.\n",
        " * Relationship between cost, reviews, and sentiments.\n",
        " * Word clouds to analyze frequent words in customer reviews.\n",
        "* Gained important business insights like:\n",
        " * **Most customers prefer mid-range restaurants (â‚¹500 - â‚¹1500)**.\n",
        " * **North Indian and Chinese cuisines are most popular**.\n",
        " * **Positive reviews dominate but neutral/negative segments provide learning points.**\n",
        "**3. Hypothesis Testing:**\n",
        "* Conducted **3 hypothesis tests** to validate business assumptions, such as:\n",
        " * **Do expensive restaurants get better reviews?**\n",
        " * **Does review length influence customer sentiment?**\n",
        " * **Do multi-cuisine restaurants receive higher ratings?**\n",
        "* Statistical tests like **ANOVA and Chi-square** confirmed/rejected assumptions with P-values and business implications.\n",
        "\n",
        "**4. Machine Learning Models:**\n",
        "Developed and evaluated three ML models:\n",
        "\n",
        " 1. **Logistic Regression** (Baseline)\n",
        " 2. **Random Forest Classifier** (Best performing model)\n",
        " 3. **Support Vector Machine (SVM)**\n",
        "\n",
        "* Performed **Cross-Validation and Hyperparameter Tuning** (GridSearchCV) for optimization.\n",
        "\n",
        "âœ… **Model Performance Summary:**\n",
        "\n",
        "**`Model`\t: `Accuracy`,\t`Precision`\t,`Recall`,\tF1-`Score`**\n",
        "1. Logistic Regression â–¶\t73.4%, 85.27%,\t73.4%,\t77.41%\n",
        "2. Random Forest (Best)â–¶\t82%,\t83.34%,\t82%,\t82.54%\n",
        "3. SVM â–¶\t73.7%,\t85.00%,\t73.7%,\t77.57%\n",
        "\n",
        "ðŸŽ¯ **Random Forest** outperformed others and was selected as the final prediction model for deployment.\n",
        "\n",
        "**5. Business Impact:**\n",
        "* **Helps Zomato analyze customer sentiments at scale**, providing real-time feedback to restaurants.\n",
        "* Assists in **targeted marketing strategie**(e.g., promoting highly-rated restaurants).\n",
        "* bEnables **automated review analysis**, reducing manual moderation efforts.\n",
        "* Insights on **cost vs. sentiment, review patterns**, and **cuisine popularity** help in strategic decisions.\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Thank You! I have successfully completed Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}